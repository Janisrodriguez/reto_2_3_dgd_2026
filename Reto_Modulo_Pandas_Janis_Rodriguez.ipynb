{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23d1ab69",
   "metadata": {},
   "source": [
    "# üöÄ Reto de Ingenier√≠a de Datos: Optimizaci√≥n y Visualizaci√≥n (M√≥dulo 1)\n",
    "**Diplomado en Estrategias de Datos - USTA**  \n",
    "\n",
    "- **Estudiante:** _[Janis Rodriguez]_  \n",
    "- **Fecha:** 2026-01-04  \n",
    "\n",
    "**Descripci√≥n:** En este cuaderno aplico t√©cnicas de *downcasting*, vectorizaci√≥n y visualizaci√≥n avanzada sobre el dataset **NYC Taxi Trip Duration** (~1.4M registros).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935c237c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from fpdf import FPDF\n",
    "\n",
    "# Configuraci√≥n: gr√°ficos n√≠tidos y estilo limpio\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16004e8c",
   "metadata": {},
   "source": [
    "## 1) Carga y diagn√≥stico de memoria (El ‚ÄúAntes‚Äù)\n",
    "\n",
    "Cargamos el dataset **sin optimizar** y medimos consumo de memoria real con `memory_usage='deep'`.  \n",
    "> Nota: **NO subas `train.csv` a GitHub** (pesa >100MB). Debe quedar solo local.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a8cc4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('data/raw/train.csv')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_train_csv():\n",
    "    candidates = [\n",
    "        Path(\"train.csv\"),\n",
    "        Path(\"data/train.csv\"),\n",
    "        Path(\"data/raw/train.csv\"),\n",
    "    ]\n",
    "    for p in candidates:\n",
    "        if p.exists():\n",
    "            return p\n",
    "    raise FileNotFoundError(f\"No encontr√© train.csv en: {candidates}\")\n",
    "\n",
    "train_path = find_train_csv()\n",
    "train_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2189e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(train_path)\n",
    "df_raw.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba5793a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagn√≥stico de memoria real (deep)\n",
    "df_raw.info(memory_usage=\"deep\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b849195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def memory_mb(df: pd.DataFrame) -> float:\n",
    "    return df.memory_usage(deep=True).sum() / (1024**2)\n",
    "\n",
    "mem_before = memory_mb(df_raw)\n",
    "mem_before\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502941a9",
   "metadata": {},
   "source": [
    "## 2) Fase 1: Optimizaci√≥n (Pandas Pro)\n",
    "\n",
    "Objetivo: **reducir al menos 50%** el consumo de memoria **sin perder informaci√≥n**.\n",
    "\n",
    "T√©cnicas:\n",
    "- Downcasting num√©rico (`int64 ‚Üí int8/int16`, `float64 ‚Üí float32` cuando aplica)\n",
    "- Conversi√≥n de `object` repetitivo a `category`\n",
    "- Parseo de fechas (datetime) de manera controlada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d8ca35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_types(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    # 1) Parseo de fechas (en el dataset suelen existir pickup_datetime y dropoff_datetime)\n",
    "    for c in [\"pickup_datetime\", \"dropoff_datetime\"]:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_datetime(df[c], errors=\"coerce\")\n",
    "\n",
    "    # 2) Downcasting num√©rico\n",
    "    int_cols = df.select_dtypes(include=[\"int64\", \"int32\", \"int16\"]).columns\n",
    "    for c in int_cols:\n",
    "        df[c] = pd.to_numeric(df[c], downcast=\"integer\")\n",
    "\n",
    "    float_cols = df.select_dtypes(include=[\"float64\"]).columns\n",
    "    for c in float_cols:\n",
    "        df[c] = pd.to_numeric(df[c], downcast=\"float\")\n",
    "\n",
    "    # 3) Objects -> category (solo si vale la pena: baja cardinalidad relativa)\n",
    "    obj_cols = df.select_dtypes(include=[\"object\"]).columns\n",
    "    n = len(df)\n",
    "    for c in obj_cols:\n",
    "        nunique = df[c].nunique(dropna=False)\n",
    "        # Heur√≠stica: si la columna tiene pocos valores √∫nicos\n",
    "        if nunique <= min(50000, max(50, int(0.5 * n))):\n",
    "            df[c] = df[c].astype(\"category\")\n",
    "\n",
    "    return df\n",
    "\n",
    "df_opt = optimize_types(df_raw)\n",
    "df_opt.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00ed94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_opt.info(memory_usage=\"deep\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a845e31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_after = memory_mb(df_opt)\n",
    "reduction = (1 - (mem_after / mem_before)) * 100\n",
    "mem_before, mem_after, reduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4848287",
   "metadata": {},
   "source": [
    "‚úÖ **Criterio**: reducci√≥n ‚â• 50%.  \n",
    "Si tu reducci√≥n es menor, revisa:\n",
    "- m√°s columnas `object` que deban ser `category`\n",
    "- columnas num√©ricas que sigan en `int64/float64`\n",
    "- leer el CSV directamente con `dtype=` (optimizaci√≥n desde la lectura).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387e29c6",
   "metadata": {},
   "source": [
    "## 3) Fase 2: Ingenier√≠a de Variables (vectorizada)\n",
    "\n",
    "Se crean variables **sin `.apply()`**, usando operaciones vectorizadas:\n",
    "\n",
    "- Variables temporales: hora, d√≠a de la semana\n",
    "- Variable geoespacial: distancia Haversine entre pickup y dropoff\n",
    "- Ejemplos de `.assign()` y `.query()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d6dd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_km(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Distancia Haversine vectorizada (km).\"\"\"\n",
    "    R = 6371.0\n",
    "    lat1 = np.radians(lat1)\n",
    "    lon1 = np.radians(lon1)\n",
    "    lat2 = np.radians(lat2)\n",
    "    lon2 = np.radians(lon2)\n",
    "\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1)*np.cos(lat2)*np.sin(dlon/2.0)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    return R * c\n",
    "\n",
    "# Nombres t√≠picos del dataset\n",
    "pickup_lat = \"pickup_latitude\"\n",
    "pickup_lon = \"pickup_longitude\"\n",
    "drop_lat = \"dropoff_latitude\"\n",
    "drop_lon = \"dropoff_longitude\"\n",
    "\n",
    "df_feat = df_opt.copy()\n",
    "\n",
    "# Variables temporales\n",
    "if \"pickup_datetime\" in df_feat.columns:\n",
    "    df_feat = df_feat.assign(\n",
    "        pickup_hour=df_feat[\"pickup_datetime\"].dt.hour.astype(\"int16\"),\n",
    "        pickup_dow=df_feat[\"pickup_datetime\"].dt.dayofweek.astype(\"int8\"),  # 0=Lunes\n",
    "        pickup_date=df_feat[\"pickup_datetime\"].dt.date\n",
    "    )\n",
    "\n",
    "# Distancia (si existen columnas)\n",
    "if all(c in df_feat.columns for c in [pickup_lat, pickup_lon, drop_lat, drop_lon]):\n",
    "    df_feat[\"haversine_km\"] = haversine_km(\n",
    "        df_feat[pickup_lat], df_feat[pickup_lon],\n",
    "        df_feat[drop_lat], df_feat[drop_lon]\n",
    "    ).astype(\"float32\")\n",
    "\n",
    "df_feat.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3488a429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de query: duraci√≥n positiva y distancia razonable (ajusta si necesitas)\n",
    "if \"trip_duration\" in df_feat.columns and \"haversine_km\" in df_feat.columns:\n",
    "    df_clean = df_feat.query(\"trip_duration > 0 and haversine_km >= 0 and haversine_km < 200\")\n",
    "else:\n",
    "    df_clean = df_feat.copy()\n",
    "\n",
    "df_clean.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506a3ea9",
   "metadata": {},
   "source": [
    "## 4) Fase 3: Visualizaci√≥n Avanzada (Storytelling)\n",
    "\n",
    "Objetivo: generar gr√°ficos que **cuenten una historia**:\n",
    "\n",
    "- **Distribuciones sesgadas** ‚Üí usar escala log\n",
    "- **Overplotting** ‚Üí transparencia (`alpha`), tama√±o (`s`) o `hexbin`\n",
    "- **Relaciones temporales** ‚Üí heatmap d√≠a vs hora\n",
    "- Limpieza de ‚Äúchartjunk‚Äù: t√≠tulos claros, ejes, `despine()`, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e9a0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASSETS = Path(\"assets\")\n",
    "ASSETS.mkdir(exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10323ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Distribuci√≥n: trip_duration (sesgada) con escala log\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "if \"trip_duration\" in df_clean.columns:\n",
    "    sns.histplot(df_clean[\"trip_duration\"], bins=100, ax=ax)\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_title(\"Distribuci√≥n de duraci√≥n de viajes (escala log)\")\n",
    "    ax.set_xlabel(\"trip_duration (seg) [log]\")\n",
    "    ax.set_ylabel(\"Frecuencia\")\n",
    "else:\n",
    "    ax.text(0.5, 0.5, \"No existe 'trip_duration' en el dataset\", ha=\"center\", va=\"center\")\n",
    "\n",
    "sns.despine()\n",
    "p1 = ASSETS / \"hist_trip_duration_log.png\"\n",
    "fig.savefig(p1, dpi=300, bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "p1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e1c27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 Overplotting geoespacial: scatter con alpha y tama√±o peque√±o\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "\n",
    "if all(c in df_clean.columns for c in [pickup_lat, pickup_lon]):\n",
    "    sample = df_clean.sample(min(100000, len(df_clean)), random_state=42)\n",
    "    ax.scatter(sample[pickup_lon], sample[pickup_lat], s=1, alpha=0.05)\n",
    "    ax.set_title(\"Pickup locations (sample) ‚Äî alpha para overplotting\")\n",
    "    ax.set_xlabel(\"pickup_longitude\")\n",
    "    ax.set_ylabel(\"pickup_latitude\")\n",
    "else:\n",
    "    ax.text(0.5, 0.5, \"No existen columnas de coordenadas\", ha=\"center\", va=\"center\")\n",
    "\n",
    "sns.despine()\n",
    "p2 = ASSETS / \"pickup_scatter_alpha.png\"\n",
    "fig.savefig(p2, dpi=300, bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "p2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cdfcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 Alternativa a overplotting: Hexbin (densidad)\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "\n",
    "if all(c in df_clean.columns for c in [pickup_lat, pickup_lon]):\n",
    "    sample = df_clean.sample(min(400000, len(df_clean)), random_state=42)\n",
    "    hb = ax.hexbin(sample[pickup_lon], sample[pickup_lat], gridsize=80, mincnt=1)\n",
    "    ax.set_title(\"Densidad de pickups (hexbin)\")\n",
    "    ax.set_xlabel(\"pickup_longitude\")\n",
    "    ax.set_ylabel(\"pickup_latitude\")\n",
    "    fig.colorbar(hb, ax=ax, label=\"conteo\")\n",
    "else:\n",
    "    ax.text(0.5, 0.5, \"No existen columnas de coordenadas\", ha=\"center\", va=\"center\")\n",
    "\n",
    "sns.despine()\n",
    "p3 = ASSETS / \"pickup_hexbin.png\"\n",
    "fig.savefig(p3, dpi=300, bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "p3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da872fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.4 Heatmap temporal: d√≠a vs hora (requiere pickup_dow y pickup_hour)\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "if all(c in df_clean.columns for c in [\"pickup_dow\", \"pickup_hour\"]):\n",
    "    pivot = (\n",
    "        df_clean.groupby([\"pickup_dow\", \"pickup_hour\"])\n",
    "        .size()\n",
    "        .reset_index(name=\"trips\")\n",
    "        .pivot(index=\"pickup_dow\", columns=\"pickup_hour\", values=\"trips\")\n",
    "        .fillna(0)\n",
    "    )\n",
    "    sns.heatmap(pivot, ax=ax)\n",
    "    ax.set_title(\"Heatmap de viajes: D√≠a de semana (filas) vs Hora (columnas)\")\n",
    "    ax.set_xlabel(\"Hora (0-23)\")\n",
    "    ax.set_ylabel(\"D√≠a de semana (0=Lun)\")\n",
    "else:\n",
    "    ax.text(0.5, 0.5, \"No existen pickup_dow/pickup_hour\", ha=\"center\", va=\"center\")\n",
    "\n",
    "sns.despine()\n",
    "p4 = ASSETS / \"heatmap_dow_hour.png\"\n",
    "fig.savefig(p4, dpi=300, bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "p4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a615371f",
   "metadata": {},
   "source": [
    "## 5) Fase 4: Capstone ‚Äî Reporte PDF autom√°tico\n",
    "\n",
    "Generamos un PDF que integra:\n",
    "- KPIs clave (filas, memoria antes/despu√©s, % reducci√≥n)\n",
    "- Visualizaciones guardadas como PNG (`assets/`)\n",
    "- Narrativa breve (storytelling)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28c5322",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT = Path(\"output\")\n",
    "OUTPUT.mkdir(exist_ok=True)\n",
    "\n",
    "kpi_total = len(df_raw)\n",
    "kpi_reduction = float(reduction)\n",
    "\n",
    "if \"pickup_hour\" in df_clean.columns:\n",
    "    top_hour = int(df_clean[\"pickup_hour\"].value_counts().idxmax())\n",
    "else:\n",
    "    top_hour = None\n",
    "\n",
    "kpi_total, kpi_reduction, top_hour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d295eeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = OUTPUT / \"reporte_reto_modulo_1.pdf\"\n",
    "\n",
    "pdf = FPDF()\n",
    "pdf.set_auto_page_break(auto=True, margin=15)\n",
    "pdf.add_page()\n",
    "\n",
    "# T√≠tulo\n",
    "pdf.set_font(\"Arial\", \"B\", 16)\n",
    "pdf.cell(0, 10, \"Reporte Autom√°tico - Reto M√≥dulo 1\", ln=True, align=\"C\")\n",
    "pdf.ln(4)\n",
    "\n",
    "# KPIs\n",
    "pdf.set_font(\"Arial\", \"\", 12)\n",
    "kpi_text = (\n",
    "    \"KPIs principales:\\n\"\n",
    "    f\"- Filas en dataset: {kpi_total:,}\\n\"\n",
    "    f\"- Memoria antes (deep): {mem_before:,.2f} MB\\n\"\n",
    "    f\"- Memoria despu√©s (deep): {mem_after:,.2f} MB\\n\"\n",
    "    f\"- Reducci√≥n: {kpi_reduction:,.2f}%\\n\"\n",
    "    f\"- Hora con m√°s pickups (si aplica): {top_hour}\\n\"\n",
    ")\n",
    "pdf.multi_cell(0, 7, kpi_text)\n",
    "\n",
    "# Insertar im√°genes\n",
    "pdf.set_font(\"Arial\", \"B\", 12)\n",
    "pdf.cell(0, 8, \"Visualizaciones clave\", ln=True)\n",
    "pdf.ln(2)\n",
    "\n",
    "for img in [p1, p2, p3, p4]:\n",
    "    if img.exists():\n",
    "        pdf.image(str(img), w=180)\n",
    "        pdf.ln(6)\n",
    "\n",
    "# Narrativa final\n",
    "pdf.set_font(\"Arial\", \"B\", 12)\n",
    "pdf.cell(0, 8, \"Hallazgos (storytelling)\", ln=True)\n",
    "pdf.set_font(\"Arial\", \"\", 12)\n",
    "pdf.multi_cell(\n",
    "    0, 7,\n",
    "    \"1) La distribuci√≥n de duraci√≥n de viajes es altamente sesgada; en escala log se observa mejor la concentraci√≥n.\\n\"\n",
    "    \"2) En el an√°lisis geoespacial, el overplotting oculta patrones; con alpha/hexbin aparece claramente la densidad.\\n\"\n",
    "    \"3) El patr√≥n temporal permite identificar horas/d√≠as con mayor demanda.\"\n",
    ")\n",
    "\n",
    "pdf.output(str(pdf_path))\n",
    "pdf_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a887dc2",
   "metadata": {},
   "source": [
    "## üí° Conclusiones y Hallazgos\n",
    "\n",
    "1. **Memoria:** Se logr√≥ reducir el dataset de `X` MB a `Y` MB (deep), con una reducci√≥n de `Z%`.\n",
    "2. **Patrones:** Se identificaron concentraciones geogr√°ficas y un patr√≥n temporal de demanda.\n",
    "3. **T√©cnica:** La vectorizaci√≥n evit√≥ `apply()` y permite escalar a millones de filas con mejor rendimiento.\n",
    "\n",
    "> Completa esta secci√≥n con tus hallazgos puntuales (m√°ximo 5‚Äì8 l√≠neas).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
